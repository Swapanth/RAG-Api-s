{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from openai import OpenAI\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import asyncio\n",
    "\n",
    "# Configuration\n",
    "FORM_RECOGNIZER_ENDPOINT = \"\"\n",
    "FORM_RECOGNIZER_KEY = \"\"\n",
    "AZURE_OPENAI_ENDPOINT = \"\"\n",
    "AZURE_OPENAI_KEY = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_analysis_client = DocumentAnalysisClient(\n",
    "    endpoint=FORM_RECOGNIZER_ENDPOINT,\n",
    "    credential=AzureKeyCredential(FORM_RECOGNIZER_KEY)\n",
    ")\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "client = OpenAI(\n",
    "    base_url=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    ")\n",
    "\n",
    "# Global storage\n",
    "vector_store = {}\n",
    "conversation_history = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(file_content):\n",
    "    \"\"\"Extract text from an uploaded file using Azure Form Recognizer.\"\"\"\n",
    "    poller = document_analysis_client.begin_analyze_document(\n",
    "        model_id=\"prebuilt-read\", \n",
    "        document=file_content\n",
    "    )\n",
    "    result = poller.result()\n",
    "    text_content = \"\"\n",
    "    \n",
    "    for page in result.pages:\n",
    "        for line in page.lines:\n",
    "            text_content += line.content + \"\\n\"\n",
    "    \n",
    "    return text_content\n",
    "\n",
    "def split_text_into_chunks(text, chunk_size=1000):\n",
    "    \"\"\"Split text into chunks of specified size.\"\"\"\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "def add_to_vector_store(file_name, chunks):\n",
    "    \"\"\"Add text chunks to vector store with TF-IDF vectorization.\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    chunk_vectors = vectorizer.fit_transform(chunks).toarray()\n",
    "    \n",
    "    vector_store[file_name] = {\n",
    "        \"chunks\": chunks,\n",
    "        \"vectors\": chunk_vectors,\n",
    "        \"feature_names\": vectorizer.get_feature_names_out()\n",
    "    }\n",
    "    print(f\"✓ Stored {len(chunks)} chunks for '{file_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search and Retrieval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_vector_store(query, top_k=3):\n",
    "    \"\"\"Search vector store for relevant chunks based on query.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for filename, file_data in vector_store.items():\n",
    "        vectorizer = TfidfVectorizer(vocabulary=file_data[\"feature_names\"])\n",
    "        query_vector = vectorizer.fit_transform([query]).toarray()\n",
    "        similarities = cosine_similarity(query_vector, file_data[\"vectors\"])[0]\n",
    "        \n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        \n",
    "        for idx in top_indices:\n",
    "            if similarities[idx] > 0.1:\n",
    "                results.append({\n",
    "                    'filename': filename,\n",
    "                    'chunk': file_data[\"chunks\"][idx],\n",
    "                    'similarity': similarities[idx]\n",
    "                })\n",
    "    \n",
    "    results.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "    return results[:top_k]\n",
    "\n",
    "def format_context(relevant_chunks):\n",
    "    \"\"\"Format retrieved chunks into context for AI.\"\"\"\n",
    "    if not relevant_chunks:\n",
    "        return \"No relevant context found in the documents.\"\n",
    "    \n",
    "    context = \"Relevant passages from the documents:\\n\\n\"\n",
    "    for i, chunk in enumerate(relevant_chunks, 1):\n",
    "        context += f\"[Document: {chunk['filename']}]\\n{chunk['chunk']}\\n\\n\"\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Response Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_response(messages):\n",
    "    \"\"\"Get response from Azure OpenAI using the new client library.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            temperature=0.1,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error getting AI response: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UI Style and Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_STYLE = \"\"\"\n",
    "    <style>\n",
    "        .chat-message {\n",
    "            margin: 12px 8px;\n",
    "            padding: 10px 16px;\n",
    "            border-radius: 20px;\n",
    "            max-width: 70%;\n",
    "            display: inline-block;\n",
    "            box-shadow: 0 1px 2px rgba(0,0,0,0.1);\n",
    "            word-wrap: break-word;\n",
    "            line-height: 1.4;\n",
    "            font-size: 15px;\n",
    "        }\n",
    "        .user-message {\n",
    "            background-color: #0084ff;\n",
    "            color: white;\n",
    "            float: right;\n",
    "            border-bottom-right-radius: 4px;\n",
    "        }\n",
    "        .assistant-message {\n",
    "            background-color: #00a67d;\n",
    "            color: white;\n",
    "            float: left;\n",
    "            border-bottom-left-radius: 4px;\n",
    "        }\n",
    "        .message-container {\n",
    "            clear: both;\n",
    "            overflow: hidden;\n",
    "            margin: 4px 0;\n",
    "            animation: fadeIn 0.3s ease;\n",
    "        }\n",
    "        @keyframes fadeIn {\n",
    "            from { opacity: 0; transform: translateY(10px); }\n",
    "            to { opacity: 1; transform: translateY(0); }\n",
    "        }\n",
    "    </style>\n",
    "\"\"\"\n",
    "\n",
    "def create_chat_interface():\n",
    "    \"\"\"Create and return chat interface widgets.\"\"\"\n",
    "    messages_area = widgets.HTML(\n",
    "        value=CHAT_STYLE + '<div style=\"height: 400px; overflow-y: auto; border: 1px solid #ddd; padding: 10px; background-color: #f8f9fa; border-radius: 8px;\"></div>'\n",
    "    )\n",
    "    \n",
    "    input_box = widgets.Text(\n",
    "        placeholder='Type your question here...',\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    send_button = widgets.Button(\n",
    "        description='Send',\n",
    "        layout=widgets.Layout(width='19%'),\n",
    "        button_style='primary'\n",
    "    )\n",
    "    \n",
    "    clear_button = widgets.Button(\n",
    "        description='Clear Chat',\n",
    "        layout=widgets.Layout(width='100%'),\n",
    "        button_style='warning'\n",
    "    )\n",
    "    \n",
    "    status_label = widgets.HTML(\n",
    "        value='<div style=\"color: gray; font-style: italic;\">Ready to chat about your documents...</div>'\n",
    "    )\n",
    "    \n",
    "    return messages_area, input_box, send_button, clear_button, status_label\n",
    "\n",
    "def create_file_upload():\n",
    "    \"\"\"Create and return file upload widget.\"\"\"\n",
    "    upload_widget = widgets.FileUpload(\n",
    "        accept='.jpg,.jpeg,.png,.pdf,.doc,.docx',\n",
    "        multiple=True,\n",
    "        description='Upload Documents'\n",
    "    )\n",
    "    \n",
    "    status_label = widgets.HTML(\n",
    "        value='<div style=\"color: gray;\">No documents uploaded yet.</div>'\n",
    "    )\n",
    "    \n",
    "    return upload_widget, status_label\n",
    "\n",
    "def add_message_to_display(messages_area, role, content):\n",
    "    \"\"\"Add a message to the chat display.\"\"\"\n",
    "    current_html = messages_area.value.split('</div>')[0]\n",
    "    message_class = 'user-message' if role == 'user' else 'assistant-message'\n",
    "    new_message = f'<div class=\"message-container\"><div class=\"chat-message {message_class}\">{content}</div></div>'\n",
    "    messages_area.value = current_html + new_message + '</div>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Application Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swapa\\AppData\\Local\\Temp\\ipykernel_12592\\2906793532.py:69: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  input_box.on_submit(lambda x: asyncio.create_task(on_send_button_click(None)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104af644d833425590cc48d4fb6e19fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Document Chat Assistant</h2>'), VBox(children=(HTML(value='<h3>1. Upload Docume…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stored 2 chunks for 'TimeTable.pdf'\n",
      "✓ Stored 4 chunks for 'Swapanth_Resumee.pdf'\n"
     ]
    }
   ],
   "source": [
    "def setup_document_chat():\n",
    "    \"\"\"Set up and display the complete document chat interface.\"\"\"\n",
    "    # Create widgets\n",
    "    upload_widget, upload_status = create_file_upload()\n",
    "    messages_area, input_box, send_button, clear_button, chat_status = create_chat_interface()\n",
    "    \n",
    "    # File upload handler\n",
    "    def handle_upload(change):\n",
    "        if isinstance(upload_widget.value, dict):  # if it's a dictionary\n",
    "            for filename, file_info in upload_widget.value.items():\n",
    "                content = file_info['content']\n",
    "                print(f\"Uploaded file: {filename}, Size: {file_info['size']} bytes\")\n",
    "                # Add your file processing code here\n",
    "        elif isinstance(upload_widget.value, tuple):  # if it's a tuple\n",
    "            for file_info in upload_widget.value:\n",
    "                filename = file_info['name']\n",
    "                content = file_info['content']\n",
    "                \n",
    "                upload_status.value = f'<div style=\"color: blue;\">Processing {filename}...</div>'\n",
    "                \n",
    "                text = extract_text(content)\n",
    "                chunks = split_text_into_chunks(text)\n",
    "                add_to_vector_store(filename, chunks)\n",
    "            \n",
    "            upload_status.value = '<div style=\"color: green;\">✓ All documents processed successfully!</div>'\n",
    "\n",
    "    async def on_send_button_click(b):\n",
    "        query = input_box.value\n",
    "        if not query.strip():\n",
    "            return\n",
    "        \n",
    "        chat_status.value = '<div style=\"color: blue;\">Processing your question...</div>'\n",
    "        add_message_to_display(messages_area, 'user', query)\n",
    "        \n",
    "        relevant_chunks = search_vector_store(query)\n",
    "        context = format_context(relevant_chunks)\n",
    "        \n",
    "        if not conversation_history:\n",
    "            conversation_history.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that answers questions based on the provided document context. \"\n",
    "                          \"Keep responses concise and relevant to the documents.\"\n",
    "            })\n",
    "        \n",
    "        conversation_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{context}\\n\\nQuestion: {query}\"\n",
    "        })\n",
    "        \n",
    "        response = get_ai_response(conversation_history)\n",
    "        conversation_history.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response\n",
    "        })\n",
    "        add_message_to_display(messages_area, 'assistant', response)\n",
    "        \n",
    "        input_box.value = ''\n",
    "        chat_status.value = '<div style=\"color: gray;\">Ready for next question...</div>'\n",
    "    \n",
    "    def on_clear_button_click(b):\n",
    "        messages_area.value = messages_area.value.split('</div>')[0] + '</div>'\n",
    "        conversation_history.clear()\n",
    "        chat_status.value = '<div style=\"color: gray;\">Chat cleared. Ready to start new conversation...</div>'\n",
    "    \n",
    "    # Connect handlers\n",
    "    upload_widget.observe(handle_upload, names='value')\n",
    "    send_button.on_click(lambda b: asyncio.create_task(on_send_button_click(b)))\n",
    "    clear_button.on_click(on_clear_button_click)\n",
    "    input_box.on_submit(lambda x: asyncio.create_task(on_send_button_click(None)))\n",
    "    \n",
    "    # Create layout\n",
    "    upload_section = widgets.VBox([\n",
    "        widgets.HTML('<h3>1. Upload Documents</h3>'),\n",
    "        upload_widget,\n",
    "        upload_status\n",
    "    ])\n",
    "    \n",
    "    chat_section = widgets.VBox([\n",
    "        widgets.HTML('<h3>2. Chat with Documents</h3>'),\n",
    "        messages_area,\n",
    "        widgets.HBox([input_box, send_button]),\n",
    "        clear_button,\n",
    "        chat_status\n",
    "    ])\n",
    "    \n",
    "    # Display interface\n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML('<h2>Document Chat Assistant</h2>'),\n",
    "        upload_section,\n",
    "        widgets.HTML('<hr>'),\n",
    "        chat_section\n",
    "    ]))\n",
    "\n",
    "# Cell 8: Run Application\n",
    "if __name__ == \"__main__\":\n",
    "    setup_document_chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
